{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/netfloator/AI_experiments/blob/main/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efffbf13",
      "metadata": {
        "id": "efffbf13"
      },
      "source": [
        "# 传统迁移学习"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd88f1c7",
      "metadata": {
        "id": "bd88f1c7"
      },
      "source": [
        "以告警派单到局向的应用作为例子，演示如何通过迁移学习来利用预训练语言模型完成特定任务。这是一个典型的多分类任务，每个局向为一个类，需要根据告警信息把告警分到某个类里。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTrY2UAzFHrq",
        "outputId": "188c8459-cabc-4d4d-9d1e-11655f6e6cf7"
      },
      "id": "gTrY2UAzFHrq",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bc12cfac",
      "metadata": {
        "id": "bc12cfac"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer,set_seed, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08ac5104",
      "metadata": {
        "id": "08ac5104"
      },
      "source": [
        "## 加载告警派单数据\n",
        "\n",
        "数据集包括143477条告警，每条包括两个字段，description字段是告警信息连接成的长串，ticket_bureau_id是要派单的局向id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "03225a0a",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "03225a0a",
        "outputId": "40f916e6-2fd2-4c06-c693-f31953db4b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3897\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Text        label\n",
              "0                     046B25-3E843046B25AAB510，终端解版  用户终端信息查询及解绑\n",
              "1        073187573029，千升万，调优后，万兆光猫光猫注册不上，麻烦帮忙看看，谢谢！     绑定设备信息查询\n",
              "2                     073198770568麻烦查下用户光猫是网口几在上网拨号     绑定设备信息查询\n",
              "3  07345486398@VOD用新机顶盒激活码注册，提示激活码与机顶盒不匹配，是哪里要解绑吗时，         查激活码\n",
              "4                         07375238760@VOD帐参解绑，要换机顶盒   机顶盒信息查询及解绑"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57549ad2-351f-4565-abee-ee211e82c777\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>046B25-3E843046B25AAB510，终端解版</td>\n",
              "      <td>用户终端信息查询及解绑</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>073187573029，千升万，调优后，万兆光猫光猫注册不上，麻烦帮忙看看，谢谢！</td>\n",
              "      <td>绑定设备信息查询</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>073198770568麻烦查下用户光猫是网口几在上网拨号</td>\n",
              "      <td>绑定设备信息查询</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07345486398@VOD用新机顶盒激活码注册，提示激活码与机顶盒不匹配，是哪里要解绑吗时，</td>\n",
              "      <td>查激活码</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07375238760@VOD帐参解绑，要换机顶盒</td>\n",
              "      <td>机顶盒信息查询及解绑</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57549ad2-351f-4565-abee-ee211e82c777')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57549ad2-351f-4565-abee-ee211e82c777 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57549ad2-351f-4565-abee-ee211e82c777');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38fd4d71-d7d5-4c93-845a-ad0b338e7a07\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38fd4d71-d7d5-4c93-845a-ad0b338e7a07')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38fd4d71-d7d5-4c93-845a-ad0b338e7a07 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "trouble_shooting_df = pd.read_excel(\"/content/drive/MyDrive/trouble_shooting_cleaned.xlsx\")\n",
        "print(len(trouble_shooting_df))\n",
        "trouble_shooting_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ce38c89",
      "metadata": {
        "id": "6ce38c89"
      },
      "source": [
        "## 数据预处理\n",
        "\n",
        "对ticket_bureau_id字段进行编码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "96cac687",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96cac687",
        "outputId": "f87d43a0-161d-4fee-a295-4a12b30adbe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(trouble_shooting_df[[\"label\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "40b59649",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40b59649",
        "outputId": "808da1c5-a5f0-4d2c-fb73-8b229019a95f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3312, 585, 3312, 585)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(trouble_shooting_df[\"Text\"], Y, test_size = 0.15)\n",
        "len(X_train), len(X_test), len(Y_train), len(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a00182a1",
      "metadata": {
        "id": "a00182a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a516c4-f9ae-4151-cfa0-4a79865fe2fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_path = \"bert-base-chinese\"\n",
        "# model_path = \"/content/drive/MyDrive/bert-trouble-shooting-007\"\n",
        "# model_path = \"nghuyong/ernie-3.0-base-zh\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_path, num_labels=len(encoder.classes_)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.add_tokens([\"IPTV\", \"OBD\", \"LOID\"], special_tokens = True)"
      ],
      "metadata": {
        "id": "74KiQgVhq_B5"
      },
      "id": "74KiQgVhq_B5",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "313d3c1a",
      "metadata": {
        "id": "313d3c1a"
      },
      "outputs": [],
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
        "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(),\n",
        "                'label': torch.tensor(label)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "682ead1d",
      "metadata": {
        "id": "682ead1d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR']\n",
        "# !pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "device = xm.xla_device()\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 16\n",
        "learning_rate = 2e-4\n",
        "num_epochs = 15\n",
        "accumulation_steps = 25\n",
        "history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "923be6b5",
      "metadata": {
        "id": "923be6b5"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, optimizer, scheduler, device, loss_to_stop = 1):\n",
        "    model.train()\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].type(torch.LongTensor).to(device)\n",
        "        # outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # outputs = torch.tensor(outputs.logits)\n",
        "        loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss # nn.CrossEntropyLoss()(outputs, labels)\n",
        "        history.append(loss.item())\n",
        "        if loss.item() <= loss_to_stop:\n",
        "          print(\"Stop on loss: \", loss.item())\n",
        "          break\n",
        "        loss.backward()\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "    optimizer.step()\n",
        "\n",
        "def evaluate(model, data_loader, device):\n",
        "    predictions, actual_labels = test(model, data_loader, device)\n",
        "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions), confusion_matrix(actual_labels, predictions)\n",
        "\n",
        "def predict(text, model, tokenizer, device, max_length=512):\n",
        "    model.eval()\n",
        "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "    return encoder.inverse_transform(preds.item())\n",
        "\n",
        "def test(model, data_loader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            predictions.extend(preds.cpu().tolist())\n",
        "            actual_labels.extend(labels.cpu().tolist())\n",
        "    return predictions, actual_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b91d417d",
      "metadata": {
        "id": "b91d417d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65db992-44be-4638-fb22-745dfa7aa353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xla:1\n"
          ]
        }
      ],
      "source": [
        "train_dataset = TextClassificationDataset(X_train.values, Y_train, tokenizer)\n",
        "val_dataset = TextClassificationDataset(X_test.values, Y_test, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model():\n",
        "  save_path = \"/content/drive/MyDrive/bert-trouble-shooting-001\"\n",
        "  model.save_pretrained(save_path)\n",
        "  tokenizer.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "472N6ijZcVpb"
      },
      "id": "472N6ijZcVpb",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c985d43d",
      "metadata": {
        "id": "c985d43d"
      },
      "outputs": [],
      "source": [
        "# 冻结除输出层和最靠近输出层的一层以外的所有层\n",
        "#for param in model.base_model.parameters():\n",
        "#    param.requires_grad = False\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "# 构建优化器\n",
        "# optimizer = AdamW([\n",
        "#    {'params': model.base_model.encoder.layer[-5:].parameters(), 'lr': 1e-3},  # 调整最靠近输出层的一层\n",
        "#    {'params': model.base_model.pooler.parameters(), 'lr': 1e-3},\n",
        "#    {'params': model.classifier.parameters(), 'lr': 1e-3}  # 调整输出层\n",
        "# ])\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps/accumulation_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5228a5bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5228a5bb",
        "outputId": "7347b2f8-7db8-4997-f186-bfa103d3b85f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1be35b58b2ca>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_to_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learning_rate: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7927995edc43>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer, scheduler, device, loss_to_stop)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# outputs = torch.tensor(outputs.logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;31m# nn.CrossEntropyLoss()(outputs, labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mloss_to_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stop on loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: From /job:tpu_worker/replica:0/task:0:\n2 root error(s) found.\n  (0) RESOURCE_EXHAUSTED: XLA:TPU compile permanent error. Ran out of memory in memory space hbm. Used 100.54G of 7.48G hbm. Exceeded hbm capacity by 93.06G.\n\nTotal hbm usage >= 101.06G:\n    reserved        530.00M \n    program         100.54G \n    arguments            0B \n\nOutput size 0B; shares 0B with arguments.\n\nProgram hbm requirement 100.54G:\n    global             4.0K\n    scoped           16.83M\n    HLO temp        100.53G (99.9% utilization: Unpadded (100.28G) Padded (100.35G), 0.2% fragmentation (180.70M))\n\n  Largest program allocations in hbm:\n\n  1. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14883.remat = copy(bitcast.44402)\n     Allocation type: HLO temp\n     ==========================\n\n  2. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14095.remat = copy(bitcast.48150)\n     Allocation type: HLO temp\n     ==========================\n\n  3. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14446.remat = copy(bitcast.46413)\n     Allocation type: HLO temp\n     ==========================\n\n  4. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14314.remat = copy(bitcast.46937)\n     Allocation type: HLO temp\n     ==========================\n\n  5. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14355.remat = copy(bitcast.46571)\n     Allocation type: HLO temp\n     ==========================\n\n  6. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14990.remat = copy(bitcast.85258)\n     Allocation type: HLO temp\n     ==========================\n\n  7. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14416.remat = copy(bitcast.46287)\n     Allocation type: HLO temp\n     ==========================\n\n  8. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14411 = copy(bitcast.46263)\n     Allocation type: HLO temp\n     ==========================\n\n  9. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14909.remat = copy(bitcast.43901)\n     Allocation type: HLO temp\n     ==========================\n\n  10. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14258.remat = copy(bitcast.47238)\n     Allocation type: HLO temp\n     ==========================\n\n  11. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14294.remat = copy(bitcast.46853)\n     Allocation type: HLO temp\n     ==========================\n\n  12. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.15295.remat = copy(bitcast.48967)\n     Allocation type: HLO temp\n     ==========================\n\n  13. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14238.remat = copy(bitcast.47154)\n     Allocation type: HLO temp\n     ==========================\n\n  14. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14202.remat = copy(bitcast.47537)\n     Allocation type: HLO temp\n     ==========================\n\n  15. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.15458.remat = copy(bitcast.48227)\n     Allocation type: HLO temp\n     ==========================\n\n  16. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14802.remat = copy(bitcast.44625)\n     Allocation type: HLO temp\n     ==========================\n\n  17. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14782.remat = copy(bitcast.44541)\n     Allocation type: HLO temp\n     ==========================\n\n  18. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14746.remat = copy(bitcast.44942)\n     Allocation type: HLO temp\n     ==========================\n\n  19. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.15153.remat = copy(bitcast.49395)\n     Allocation type: HLO temp\n     ==========================\n\n  20. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.15173.remat = copy(bitcast.49479)\n     Allocation type: HLO temp\n     ==========================\n\n\n\t [[{{node XRTCompile}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n  (1) RESOURCE_EXHAUSTED: XLA:TPU compile permanent error. Ran out of memory in memory space hbm. Used 100.54G of 7.48G hbm. Exceeded hbm capacity by 93.06G.\n\nTotal hbm usage >= 101.06G:\n    reserved        530.00M \n    program         100.54G \n    arguments            0B \n\nOutput size 0B; shares 0B with arguments.\n\nProgram hbm requirement 100.54G:\n    global             4.0K\n    scoped           16.83M\n    HLO temp        100.53G (99.9% utilization: Unpadded (100.28G) Padded (100.35G), 0.2% fragmentation (180.70M))\n\n  Largest program allocations in hbm:\n\n  1. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14883.remat = copy(bitcast.44402)\n     Allocation type: HLO temp\n     ==========================\n\n  2. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14095.remat = copy(bitcast.48150)\n     Allocation type: HLO temp\n     ==========================\n\n  3. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14446.remat = copy(bitcast.46413)\n     Allocation type: HLO temp\n     ==========================\n\n  4. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14314.remat = copy(bitcast.46937)\n     Allocation type: HLO temp\n     ==========================\n\n  5. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14355.remat = copy(bitcast.46571)\n     Allocation type: HLO temp\n     ==========================\n\n  6. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14990.remat = copy(bitcast.85258)\n     Allocation type: HLO temp\n     ==========================\n\n  7. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14416.remat = copy(bitcast.46287)\n     Allocation type: HLO temp\n     ==========================\n\n  8. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14411 = copy(bitcast.46263)\n     Allocation type: HLO temp\n     ==========================\n\n  9. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14909.remat = copy(bitcast.43901)\n     Allocation type: HLO temp\n     ==========================\n\n  10. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14258.remat = copy(bitcast.47238)\n     Allocation type: HLO temp\n     ==========================\n\n  11. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.14294.remat = copy(bitcast.46853)\n     Allocation type: HLO temp\n     ==========================\n\n  12. Size: 192.00M\n     Shape: f32[16,12,512,512]{3,2,1,0:T(8,128)}\n     Unpadded size: 192.00M\n     XLA label: copy.15295.remat = copy(bitcast.4896"
          ]
        }
      ],
      "source": [
        "# num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    train(model, train_dataloader, optimizer, scheduler, device, loss_to_stop = 0.1)\n",
        "    print(\"learning_rate: \", scheduler.get_lr())\n",
        "    accuracy, report, cm = evaluate(model, val_dataloader, device)\n",
        "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "    save_model()\n",
        "    # print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e30c3b1",
      "metadata": {
        "id": "9e30c3b1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#history = history[200:]\n",
        "plt.plot(range(len(history)),history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler.get_lr()"
      ],
      "metadata": {
        "id": "TesfkP6ce1kM"
      },
      "id": "TesfkP6ce1kM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy, report, cm = evaluate(model, val_dataloader, device)\n",
        "display = ConfusionMatrixDisplay(cm)\n",
        "fig, ax = plt.subplots(figsize=(30,30))\n",
        "display.plot(ax = ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FD3LW11iD-tu"
      },
      "id": "FD3LW11iD-tu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confused_labels = []\n",
        "for actual_label in range(len(cm)):\n",
        "    for pred in range(len(cm[actual_label])):\n",
        "        if cm[actual_label][pred] >= 4 and actual_label != pred:\n",
        "            print(f\"{pred} : {actual_label} - {cm[actual_label][pred]} - {encoder.classes_[pred]},{encoder.classes_[actual_label]}\")\n",
        "            confused_labels.append((pred, actual_label))"
      ],
      "metadata": {
        "id": "Xzj_DMQKdeLk"
      },
      "id": "Xzj_DMQKdeLk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred,_ = test(model, val_dataloader, device)\n",
        "Y_pred = np.array(Y_pred)\n",
        "for pred,actual_label in confused_labels:\n",
        "    print(\"predicted: \", encoder.classes_[pred], \":::::::::::: actual: \", encoder.classes_[actual_label])\n",
        "    print(X_test[(Y_pred == pred) & (Y_test == actual_label)])"
      ],
      "metadata": {
        "id": "yYA62uu0ETjr"
      },
      "id": "yYA62uu0ETjr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# regex = r\"解绑.+?光猫|光猫.+?解绑\"\n",
        "regex = r\"(机顶盒)?.+?激活码\"\n",
        "# trouble_shooting_df[[True if re.search(regex, x) else False for x in trouble_shooting_df[\"Text\"]]].groupby(by=\"label\").count()\n",
        "trouble_shooting_df[[True if \"机顶盒\" in x and \"激活码\" in x else False for x in trouble_shooting_df[\"Text\"]]].groupby(by=\"label\").count()\n",
        "# trouble_shooting_df[[True if re.search(regex, x) else False for x in trouble_shooting_df[\"Text\"]] & (trouble_shooting_df[\"label\"] != \"查激活码\")]"
      ],
      "metadata": {
        "id": "wJOmvgytgorV"
      },
      "id": "wJOmvgytgorV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64_8i32iEjYl"
      },
      "id": "64_8i32iEjYl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "301px",
        "width": "352px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "249px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}